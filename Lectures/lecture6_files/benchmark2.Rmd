---
title: "Benchmarking split-apply-combine"
author: "Abhijit Dasgupta"
date: "10/26/2016"
output: html_document
---
---
title: "Benchmarking data reading"
author: "Abhijit Dasgupta"
date: "10/26/2016"
output: html_document
---
<style type="text/css">
.table {
  width: 50%;
  margin-left:auto;
  margin-right:auto;
}
blockquote {
  width: 90%;
  margin-left:auto;
  margin-right:auto;
  background-color: lightgrey;
  font-size: 100%;
  font-style: italic;
}
</style>

```{r setup, echo=F}
knitr::opts_chunk$set(echo = T,
                      eval = F,
                      warning=F,
                      message = F,
                      comment = '> ',
                      cache=T)
```
```{r read, eval=F, echo=F}
load('benchmarking.rda')
```
```{r, message=F, warning=F, cache=F}
# Loading packages we will need in this exercise

library(rbenchmark) # Benchmarking package
library(reshape2)
library(dplyr)
library(tidyr) # Hadley's package for reshaping tidy data
library(data.table) # an alternative package by Matt Dowle
                    # for storing and manipulating data. It 
                    # stores data in a data.table object rather
                    # than a data.frame object
```

## Introduction

We are going to repeat our exercise of getting the p-values of multiple t-tests from an 
expression data set as we did in [Lecture 6](../lecture6.html). However, now, we will use the full
dataset, which has 12553 proteins, rather than just the 10 we were looking at before. So we are going to get 12553 p-values by doing 12553 t-tests comparing expression between ER-positive and ER-negative patients. In this article we will benchmark the split-apply-combine process of getting p-values

## Reading the data into R

This data set is stored as a compressed (zipped) file called _fullExpression.zip_, which is 3.6Mb. The actual data is not huge, but is still 13Mb when stored as a text (csv) file. 

We will use the `fread` function from the `data.table` package to read the data
```{r}
library(data.table)
if(!file.exists('BreastCancer_Expression_full.csv')){ # Check if the file already exists
  unzip('../lecture6_data/fullExpression.zip',
        'BreastCancer_Expression_full.csv', # Specify the file to be extracted
        exdir = '.') # Specify the directory where it will be extracted
}
expression_dat <- fread('BreastCancer_Expression_full.csv') # fread creates a data.table
expression_dat <- as.data.frame(expression_dat) # we convert it to a data.frame
expression_dat <- expression_dat[-(1:3),] # remove 1st three rows (to avoid duplicates)
```

## Merging the data with the clinical data

```{r}
clinical_dat <- read.csv('../lecture6_data/BreastCancer_Clinical.csv', 
                         stringsAsFactors=F)
full_dat <- merge(clinical_dat, expression_dat, 
                  by.x = 'Complete.TCGA.ID', by.y='TCGA_ID')
```

## Reshaping the data
```{r}
library(reshape2)
library(dplyr)
reshaped_dat <- melt(full_dat, id.vars = c('Complete.TCGA.ID','ER.Status'),
                     measure.vars = starts_with('NP', vars=names(full_dat)))
```

## Split-apply-combine

Recall from [Lecture 6](../lecture6.html) that we will split `reshaped_dat` by the protein id, then run a t-test comparing the expression level of the protein between ER-positive and ER-negative individuals, extract p-values and combine them into a final data set. There are quite a few options to do this in R, in addition to the one I showed in class. I'll demonstrate a few here.

> **Note:** I will write each method to do the split-apply-combine as a function, so we can benchmark them easily later

First, let's recall the function we used to run the t-test and return its p-value from class

```{r t-test}
run_t_test <- function(d){
  test <- t.test(value ~ ER.Status, data=d)
  pvalue <- test$p.value
  return(data.frame(pvalue=pvalue))
}
```

### The way we did in class

```{r sac}
option1 <- function(){
  split_data <- split(reshaped_dat, reshaped_dat$variable)
  pvalues <- lapply(split_data, run_t_test)
  pvalues_final <- plyr::ldply(pvalues)
  return(pvalues_final)
}
```

### Using a `for` loop in a "naive" fashion
```{r for}
option2 <- function(){
  u <- unique(reshaped_dat$variable)
  pval <- rep(0, length(u)) # always efficient to pre-assign a vector
  for (i in 1:length(u)){
    pval[i] <- run_t_test(subset(reshaped_dat, variable==u[i]))
  }
  pvalues_final <- data.frame(variable = u, pvalue=pval)
  return(pvalues_final)
}
```

### Using a for loop instead of lapply
```{r no-lapply}
option3 <- function(){
  split_data <- split(reshaped_dat, reshaped_dat$variable)
  pval <- rep(0, length(split_data))
  for(i in 1:length(split_data)){
    pval[i] <- run_t_test(split_data[[i]])
  }
  pvalues_final <- data.frame(variable = names(split_data), pvalue = pval)
  return(pvalues_final)
}
```

### Using plyr::ddply

The `ddply` function inputs a data.frame, the variable to _split_ it by, and the function to _apply_ to 
each split data.frame component, and outputs a data.frame that _combines_ the result. 
```{r plyr}
option4 <- function(){
  pvalues_final <- plyr::ddply(reshaped_dat, ~variable, run_t_test)
  return(pvalues_final)
}
```

### Using the `group_by` and `do` functions in `dplyr`
The `group_by` function does the _splitting_, and the `do` function _applies_ a function to each component and _combines_ them, as long as the output of that function is a scalar or a data.frame object. The `.` within the `do` function represents the data.frame component in the split data frame that is input into `run_t_test`.

```{r dplyr }
option5 <- function(){
  require(dplyr)
  grouped <- group_by(reshaped_dat, variable)
  pvalues_final <- do(grouped, run_t_test(.))
  return(pvalues_final)
}
```

### Using the `by` function in base R
```{r}
option6 <- function(){
  pvalues <- by(reshaped_dat, factor(reshaped_dat[,'variable']), run_t_test)
  pvalues_final <- plyr::ldply(unclass(pvalues))
  return(pvalues_final)
}
```

### Using `data.table`
The `data.table` package actually has a rather odd syntax, which I won't explain here, or in class. If you want to know more about this package, come talk to me later. 
```{r data.table }
option7 <- function(){
  require(data.table)
  reshaped_dt <- data.table(reshaped_dat)
  pvalues_final <- reshaped_dt[,run_t_test(.SD), by=variable]
  pvalues_final <- as.data.frame(pvalues_final)
  return(pvalues_final)
}
```

We will now compare timings of these 7 options. I've verified that results from all the functions are the same, except for some re-ordering of rows. We will use the `rbenchmark` package for this 

```{r}
library(rbenchmark)
benchmark_sac <- benchmark(
  'classroom' = option1(),
  'for loop (naive)' = option2(),
  'for loop (list)' = option3(),
  'ddply' = option4(),
  'dplyr group_by' = option5(),
  'by' = option6(),
  'data.table' = option7(),
  columns = c('test','elapsed','replications','relative'),
  order = 'elapsed'
)

knitr::kable(benchmark_sac)
```
```{r}
knitr::kable(benchmark_sac)
```


